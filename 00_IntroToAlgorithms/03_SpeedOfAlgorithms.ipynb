{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Speed of Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1\n",
    "\n",
    "In computer science and programming, we’re always looking for “good” solutions. \n",
    "- Sometimes we're interested in measuring this in terms of the number of computations.\n",
    "- Other times we are just interested in the algorithm that takes the least amount of time as measured by a stopwatch.\n",
    "\n",
    "Recall that if you're comparing two methods, the impact of $n^2$ versus $n$ can drastically change as we increase *n*. At the beginning, we might not notice any notable differences and are only able to witness the impact of the two algorithms once we increase the sample size.\n",
    "\n",
    "It's important to not make a decision between two algorithms when the sample size is not large because it can be misrepresented. We need to await for the algorithm performance when the sample size increases to evalualate the better performing algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "\n",
    "Two different big Os communicate to a computer scientist that the two functions below are very different.\n",
    "- Algorithm Q takes a quadratic amount of time to run, so it would be common to call it a quadratic-time algorithm. \n",
    "- Algorithm L, similarly, would be called a logarithmic-time algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3\n",
    "\n",
    "- Big O Interpretation/Use:\n",
    "    - Big O notation is a **formal, mathematical** way of describing how functions grow.\n",
    "    - Big O notation is an **informal, conversational** language that computer scientists use ubiquitously to describe how fast algorithms run.\n",
    "\n",
    "\n",
    "- Formal/Mathematical:\n",
    "    - $O(g(n))$ is a set of functions. Any other function $f(n)$ is in the set $O(g(n))$ if the ratio between $f$ and $g$, $f(n)/g(n)$ eventually goes and stays at or below some constant $C$ as $n$ gets very large.\n",
    "    - The main idea is that even if there are function that are not exactly linear, say $3n+1$, it would still be considered as linear in big o notation\n",
    "    - For example, $f(n) = 3n+1$ is in $O(n)$ because the ratio of $f(n)$ and $g(n)$ = $n$ stays at or below $C=4$ as long as $n>=1$\n",
    "    - If you think about in a graph, we know that the value of $3n+1$ will always be larger than 3 so we have to choose another constant, $C$ that we can apply (it can be any $C$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T12:28:30.838804Z",
     "start_time": "2019-05-24T12:28:30.832951Z"
    }
   },
   "source": [
    "## Section 4\n",
    "\n",
    "**The specific constant doesn't matter for big O. We could have picked the constant  for both examples above, and that would have also been correct.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5\n",
    "\n",
    "Note: The algorithms that are used above only indicates that the worst case scenario. In reality, we might view different results. \n",
    "- For example, if we have three algorithms, $O(n)$, $O(2^n)$, and $O(logn)$, when we are computing some calculation, they might all take the same amount time of $O(logn)$ because $logn \\in O(logn)$, $logn \\in O(n)$, and $logn \\in O(2^n)$. Thus, it's entirely possible that the computation is the same for all 3 algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6\n",
    "\n",
    "For the classification of the big O classification for polynomial functions, we simply only look at the biggest exponent.\n",
    "- $(n^5/1000) + 1000n^4 + 300n^2 + 20n + 5$\n",
    "- In the equation above, we would claim that the polynomial has degree 5 because of the $(n^5/1000)$ \n",
    "- Informally, this is because larger exponents grow much faster than smaller exponents. They grow so much faster that we can effectively ignore the smaller exponents as  gets really big.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7\n",
    "\n",
    "- **Big O is a mathematical notation for talking about sets of functions by giving an upper limit to how fast those functions can grow.**\n",
    "- **Big O is an informal way that computer scientists talk about how much an algorithm is expected to slow down as the algorithm is given bigger and bigger inputs.**"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
